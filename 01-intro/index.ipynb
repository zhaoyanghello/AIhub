{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nOf4rvQ13si"
   },
   "source": [
    "## 一、什么是 AI？\n",
    "\n",
    "<img src=\"./ai-timeline.png\" style=\"margin-left: 0px\" width=\"800px\">\n",
    "\n",
    "> 「深蓝」的创造者许峰雄博士说过：「AI is bullshit。深蓝没用任何 AI 算法，就是硬件穷举棋步。」\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>思考：</b>你觉得哪些应用算是 AI？\n",
    "</div>\n",
    "\n",
    "一种观点：基于机器学习、神经网络的是 AI，基于规则、搜索的不是 AI。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nOf4rvQ13si"
   },
   "source": [
    "## 二、大模型能干什么？\n",
    "\n",
    "大模型，全称「大语言模型」，英文「Large Language Model」，缩写「LLM」。\n",
    "\n",
    "现在，已经不需要再演示了。每人应该都至少和下面一个基于大模型的对话产品，对话过至少 100 次。\n",
    "\n",
    "| 国家 | 对话产品           | 大模型         | 链接                                                             |\n",
    "| ---- | ------------------ | -------------- | ---------------------------------------------------------------- |\n",
    "| 美国 | OpenAI ChatGPT     | GPT-3.5、GPT-4 | [https://chat.openai.com/](https://chat.openai.com/)             |\n",
    "| 美国 | Microsoft Copilot  | GPT-4 和未知   | [https://copilot.microsoft.com/](https://copilot.microsoft.com/) |\n",
    "| 美国 | Google Bard        | Gemini         | [https://bard.google.com/](https://bard.google.com/)             |\n",
    "| 中国 | 百度文心一言       | 文心 4.0       | [https://yiyan.baidu.com/](https://yiyan.baidu.com/)             |\n",
    "| 中国 | 讯飞星火           | 星火 3.5       | [https://xinghuo.xfyun.cn/](https://xinghuo.xfyun.cn/)           |\n",
    "| 中国 | 智谱清言           | GLM-4          | [https://chatglm.cn/](https://chatglm.cn/)                       |\n",
    "| 中国 | 月之暗面 Kimi Chat | Moonshot       | [https://kimi.moonshot.cn/](https://kimi.moonshot.cn/)           |\n",
    "| 中国 | MiniMax 星野       | abab6          | [https://www.xingyeai.com/](https://www.xingyeai.com/)           |\n",
    "\n",
    "本课第一个专业向要求：分清**对话产品**和**大模型**。\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>建议：</b>\n",
    "<ul>\n",
    "<li>建议要有一个访问国外的「通道」，否则无法有顶级体验</li>\n",
    "<li>如果不能访问 ChatGPT，不是 ChatGPT Plus 会员，会非常遗憾</li>\n",
    "<li><a href=\"https://copilot.microsoft.com/\">Microsoft Copilot</a> 是 ChatGPT 免费平替，用的也是宇宙最强 GPT-4 大模型</li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "\n",
    "但是，千万别以为大模型只是聊天机器人。它的能量，远不止于此。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nOf4rvQ13si"
   },
   "source": [
    "### 2.1、按格式输出\n",
    "\n",
    "<img src=\"./gpt-ner.png\" style=\"margin-left: 0px\">\n",
    "\n",
    "### 2.2、分类\n",
    "\n",
    "<img src=\"./gpt-classification.png\" style=\"margin-left: 0px\" width=600px>\n",
    "\n",
    "### 2.3、聚类\n",
    "\n",
    "<img src=\"./gpt-clustering.png\" style=\"margin-left: 0px\" width=600px>\n",
    "\n",
    "### 2.4、持续互动\n",
    "\n",
    "<img src=\"./gpt-decision.png\" style=\"margin-left: 0px\" width=600px>\n",
    "\n",
    "### 2.5、技术相关问题\n",
    "\n",
    "<img src=\"./gpt-plan.png\" style=\"margin-left: 0px\" width=600px>\n",
    "\n",
    "### 2.6、更多举例\n",
    "\n",
    "- **舆情分析：**从公司产品的评论中，分析哪些功能/元素是用户讨论最多的，评价是正向还是负向\n",
    "- **坐席质检：**检查客服/销售人员与用户的对话记录，判断是否有争吵、辱骂、不当言论，话术是否符合标准\n",
    "- **知识库：**让大模型基于私有知识回答问题\n",
    "- **零代码开发/运维：**自动规划任务，生成指令，自动执行\n",
    "- **AI 编程：**用 AI 编写代码，提升开发效率\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>思考：</b>你的业务中，有哪些问题可以用 AI 解决？\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nOf4rvQ13si"
   },
   "source": [
    "### 2.7、可能一切问题，都能解决，所以是 AGI（Artificial General Intelligence）\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<b>划重点：</b>\n",
    "<ol>\n",
    "<li>把大模型看做是一个函数，给输入，<b>生成</b>输出</li>\n",
    "<li>任何问题，都可以用语言描述，成为大模型的输入，就能<b>生成</b>问题的结果</li>\n",
    "</ol>\n",
    "</div>\n",
    "\n",
    "这当然还是美好的理想，但正在无限逼近。我们很幸运，能亲历这个过程。\n",
    "\n",
    "当下，如何发挥大模型的现有能力呢？最大障碍是没有形成认知对齐。\n",
    "\n",
    "<img src=\"./landing.jpg\" style=\"margin-left: 0px\" width=700px>\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<b>找落地场景的思路：</b>\n",
    "<ol>\n",
    "<li>从最熟悉的领域入手</li>\n",
    "<li>让 AI 学最厉害员工的能力，再让 ta 辅助其他员工，实现降本增效</li>\n",
    "<li>找「文本进、文本出」的场景</li>\n",
    "<li>别求大而全。将任务拆解，先解决小任务、小场景（周鸿祎：「小切口，大纵深」）</li>\n",
    "</ol>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nOf4rvQ13si"
   },
   "source": [
    "## 三、大模型是怎么生成结果的？\n",
    "\n",
    "### 3.1、通俗原理\n",
    "\n",
    "其实，它只是根据上文，猜下一个词（的概率）……\n",
    "\n",
    "<img src=\"./lm-autoregressive.gif\" style=\"margin-left: 0px\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nOf4rvQ13si"
   },
   "source": [
    "OpenAI 的接口名就叫「completion」，也证明了其只会「生成」的本质。\n",
    "\n",
    "下面用程序演示「生成下一个字」。你可以自己修改 prompt 试试。还可以使用相同的 prompt 运行多次。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "APIConnectionError",
     "evalue": "Connection error.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\httpx\\_transports\\default.py\u001b[0m in \u001b[0;36mmap_httpcore_exceptions\u001b[1;34m()\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[1;32myield\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\httpx\\_transports\\default.py\u001b[0m in \u001b[0;36mhandle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mmap_httpcore_exceptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m             \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\httpcore\\_sync\\connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    215\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_close_connections\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclosing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mexc\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\httpcore\\_sync\\connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    195\u001b[0m                     \u001b[1;31m# Send the request on the assigned connection.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                     response = connection.handle_request(\n\u001b[0m\u001b[0;32m    197\u001b[0m                         \u001b[0mpool_request\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\httpcore\\_sync\\http_proxy.py\u001b[0m in \u001b[0;36mhandle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    288\u001b[0m                 )\n\u001b[1;32m--> 289\u001b[1;33m                 connect_response = self._connection.handle_request(\n\u001b[0m\u001b[0;32m    290\u001b[0m                     \u001b[0mconnect_request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\httpcore\\_sync\\connection.py\u001b[0m in \u001b[0;36mhandle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     98\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_connect_failed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\httpcore\\_sync\\connection.py\u001b[0m in \u001b[0;36mhandle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     75\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_connection\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m                     \u001b[0mstream\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_connect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\httpcore\\_sync\\connection.py\u001b[0m in \u001b[0;36m_connect\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    153\u001b[0m                     \u001b[1;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"start_tls\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m                         \u001b[0mstream\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_tls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    155\u001b[0m                         \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturn_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\httpcore\\_backends\\sync.py\u001b[0m in \u001b[0;36mstart_tls\u001b[1;34m(self, ssl_context, server_hostname, timeout)\u001b[0m\n\u001b[0;32m    167\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mSyncStream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msock\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\httpcore\\_exceptions.py\u001b[0m in \u001b[0;36mmap_exceptions\u001b[1;34m(map)\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfrom_exc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mto_exc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[1;32mraise\u001b[0m  \u001b[1;31m# pragma: nocover\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectError\u001b[0m: EOF occurred in violation of protocol (_ssl.c:1125)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mConnectError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\openai\\_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    925\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 926\u001b[1;33m             response = self._client.send(\n\u001b[0m\u001b[0;32m    927\u001b[0m                 \u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\httpx\\_client.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 914\u001b[1;33m         response = self._send_handling_auth(\n\u001b[0m\u001b[0;32m    915\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\httpx\\_client.py\u001b[0m in \u001b[0;36m_send_handling_auth\u001b[1;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[0;32m    941\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m                 response = self._send_handling_redirects(\n\u001b[0m\u001b[0;32m    943\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\httpx\\_client.py\u001b[0m in \u001b[0;36m_send_handling_redirects\u001b[1;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[0;32m    978\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 979\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_single_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    980\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\httpx\\_client.py\u001b[0m in \u001b[0;36m_send_single_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m   1014\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1015\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransport\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1016\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\httpx\\_transports\\default.py\u001b[0m in \u001b[0;36mhandle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mmap_httpcore_exceptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m             \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\httpx\\_transports\\default.py\u001b[0m in \u001b[0;36mmap_httpcore_exceptions\u001b[1;34m()\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mmapped_exc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectError\u001b[0m: EOF occurred in violation of protocol (_ssl.c:1125)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mAPIConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-6ee9877451e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprompt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"今天我很\"\u001b[0m  \u001b[1;31m# 改我试试\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m response = client.completions.create(\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"gpt-3.5-turbo-instruct\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mprompt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\openai\\_utils\\_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    273\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 275\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[1;31m# type: ignore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\openai\\resources\\completions.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, model, prompt, best_of, echo, frequency_penalty, logit_bias, logprobs, max_tokens, n, presence_penalty, seed, stop, stream, suffix, temperature, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    514\u001b[0m         \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m|\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTimeout\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m|\u001b[0m \u001b[0mNotGiven\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNOT_GIVEN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m     ) -> Completion | Stream[Completion]:\n\u001b[1;32m--> 516\u001b[1;33m         return self._post(\n\u001b[0m\u001b[0;32m    517\u001b[0m             \u001b[1;34m\"/completions\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m             body=maybe_transform(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\openai\\_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1206\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"post\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1207\u001b[0m         )\n\u001b[1;32m-> 1208\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1210\u001b[0m     def patch(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\openai\\_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    895\u001b[0m         \u001b[0mstream_cls\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_StreamT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    896\u001b[0m     ) -> ResponseT | _StreamT:\n\u001b[1;32m--> 897\u001b[1;33m         return self._request(\n\u001b[0m\u001b[0;32m    898\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m             \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\openai\\_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    948\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mretries\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 950\u001b[1;33m                 return self._retry_request(\n\u001b[0m\u001b[0;32m    951\u001b[0m                     \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\openai\\_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1019\u001b[0m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1020\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m         return self._request(\n\u001b[0m\u001b[0;32m   1022\u001b[0m             \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\openai\\_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    948\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mretries\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 950\u001b[1;33m                 return self._retry_request(\n\u001b[0m\u001b[0;32m    951\u001b[0m                     \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\openai\\_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1019\u001b[0m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1020\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m         return self._request(\n\u001b[0m\u001b[0;32m   1022\u001b[0m             \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\openai\\_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    959\u001b[0m             \u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Raising connection error\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 960\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAPIConnectionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    961\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m         log.debug(\n",
      "\u001b[1;31mAPIConnectionError\u001b[0m: Connection error."
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "#from dotenv import load_dotenv,find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key = \"sk-COfXKJ3FshQbCrS4eRLWJ2R6fndZVPHOXk1HamEZXssAqh8C\",\n",
    "    base_url = \"https://api.fe8.cn/v1\"\n",
    ")\n",
    "\n",
    "prompt = \"今天我很\"  # 改我试试\n",
    "response = client.completions.create(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    prompt=prompt,\n",
    "    max_tokens=512,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    print(chunk.choices[0].text, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2、略深一点的通俗原理\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<p>用不严密但通俗的语言描述大模型的工作原理：</p>\n",
    "<ol>\n",
    "<li>大模型阅读了人类曾说过的所有的话。这就是「<b>机器学习</b>」，这个过程叫「<b>训练</b>」</li>\n",
    "<li>把一串 token 后面跟着的不同 token 的概率存入「<b>神经网络</b>」。保存的数据就是「<b>参数</b>」，也叫「<b>权重</b>」</li>\n",
    "<li>当我们给它若干 token，大模型就能算出概率最高的下一个 token 是什么。这就是「<b>生成</b>」，也叫「<b>推理</b>」</li>\n",
    "<li>用生成的 token，再加上上文，就能继续生成下一个 token。以此类推，生成更多文字</li>\n",
    "</ol>\n",
    "</div>\n",
    "\n",
    "Token 是什么？\n",
    "\n",
    "1. 可能是一个英文单词，也可能是半个，三分之一个\n",
    "2. 可能是一个中文词，或者一个汉字，也可能是半个汉字，甚至三分之一个汉字\n",
    "3. 大模型在开训前，需要先训练一个 tokenizer 模型。它能把所有的文本，切成 token\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>思考：</b>\n",
    "<ol>\n",
    "<li>AI 做对的事，怎么用这个原理解释？</li>\n",
    "<li>AI 的幻觉，一本正经地胡说八道，怎么用这个原理解释？</li>\n",
    "</ol>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3、再深一点点\n",
    "\n",
    "这套生成机制的内核叫「Transformer 架构」。但其实，transformer 已经不是最先进的了。\n",
    "\n",
    "| 架构        | 设计者                                               | 特点                                     | 链接                                                                                                   |\n",
    "| ----------- | ---------------------------------------------------- | ---------------------------------------- | ------------------------------------------------------------------------------------------------------ |\n",
    "| Transformer | Google                                               | 最流行，几乎所有大模型都用它             | [OpenAI 的代码](https://github.com/openai/finetune-transformer-lm/blob/master/train.py)                |\n",
    "| RWKV        | [PENG Bo](https://www.zhihu.com/people/bopengbopeng) | 可并行训练，推理性能极佳，适合在端侧使用 | [官网](https://www.rwkv.com/)、[RWKV 5 训练代码](https://github.com/BlinkDL/RWKV-LM/tree/main/RWKV-v5) |\n",
    "| Mamba       | CMU & Princeton University                           | 性能更佳，尤其适合长文本生成             | [GitHub](https://github.com/state-spaces/mamba)                                                        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四、用好 AI 的核心心法\n",
    "\n",
    "OpenAI 首席科学家 Ilya Sutskever 说过：\n",
    "\n",
    "> 数字神经网络和人脑的生物神经网络，在数学原理上是一样的。\n",
    "\n",
    "所以，我们要：\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "把 AI 当人看。<br>\n",
    "把 AI 当人看。<br>\n",
    "把 AI 当人看。\n",
    "</div>\n",
    "\n",
    "我和凯文·凯利交流时，他说了类似的观点：「和人怎么相处，就和 AI 怎么相处。」\n",
    "\n",
    "1. 用「当人看」来理解 AI\n",
    "2. 用「当人看」来控制 AI\n",
    "3. 用「当人看」来说服用户正确看待 AI 的不足\n",
    "\n",
    "这是贯彻整门课，甚至我们与 AI 为伴的生涯的心法。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nOf4rvQ13si"
   },
   "source": [
    "## 五、大模型应用架构\n",
    "\n",
    "大模型技术分两个部分：\n",
    "\n",
    "1. **训练基础大模型**：全世界只需要 1000 人做这个\n",
    "2. **建造大模型应用**：所有技术人，甚至所有人，都需要掌握\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "大模型应用技术特点：<strong>门槛低，天花板高。</strong>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1、典型业务架构\n",
    "\n",
    "<img src=\"./business_arch.webp\" style=\"margin-left: 0px\" width=700px>\n",
    "\n",
    "Agent 还太超前，Copilot 值得追求。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2、技术架构\n",
    "\n",
    "#### 纯 Prompt\n",
    "\n",
    "就像和一个人对话，你说一句，ta 回一句，你再说一句，ta 再回一句……\n",
    "\n",
    "<img src=\"./prompt_arch.png\" style=\"margin-left: 0px\" width=300px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agent + Function Calling\n",
    "\n",
    "- Agent：AI 主动提要求\n",
    "- Function Calling：AI 要求执行某个函数\n",
    "- 场景举例：你问过年去哪玩，ta 先反问你有多少预算\n",
    "\n",
    "<img src=\"./func_arch.png\" style=\"margin-left: 0px\" width=600px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RAG（Retrieval-Augmented Generation）\n",
    "\n",
    "- Embeddings：把文字转换为更易于相似度计算的编码。这种编码叫**向量**\n",
    "- 向量数据库：把向量存起来，方便查找\n",
    "- 向量搜索：根据输入向量，找到最相似的向量\n",
    "- 场景举例：考试时，看到一道题，到书上找相关内容，再结合题目组成答案。然后，就都忘了\n",
    "\n",
    "<img src=\"./embeddings_arch.png\" style=\"margin-left: 0px\" width=700px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine-tuning\n",
    "\n",
    "努力学习考试内容，长期记住，活学活用。\n",
    "\n",
    "<img src=\"./tech_arch.png\" style=\"margin-left: 0px\" width=700px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###5.3、如何选择技术路线\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "面对一个需求，如何选择技术方案？下面是个不严谨但常用思路。\n",
    "\n",
    "<img src=\"./tech_solution.png\" style=\"margin-left: 0px\" width=700px>\n",
    "\n",
    "值得尝试 Fine-tuning 的情况：\n",
    "\n",
    "1. 提高大模型的稳定性\n",
    "2. 用户量大，降低推理成本的意义很大\n",
    "3. 提高大模型的生成速度\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基础模型选型，也是个重要因素。合规和安全是首要考量因素。\n",
    "\n",
    "| 需求             | 国外大模型 | 国产大模型 | 开源大模型 |\n",
    "| ---------------- | ---------- | ---------- | ---------- |\n",
    "| 国内 2C          | 🛑         | ✅         | ✅         |\n",
    "| 国内 2G          | 🛑         | ✅         | ✅         |\n",
    "| 国内 2B          | ✅         | ✅         | ✅         |\n",
    "| 出海             | ✅         | ✅         | ✅         |\n",
    "| 数据安全特别重要 | 🛑         | 🛑         | ✅         |\n",
    "\n",
    "然后用测试数据，在可以选择的模型里，做测试，找出最优。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AI 全栈课程主要以 OpenAI 为例，少量介绍国产大模型，微调会讲开源大模型。因为：\n",
    "\n",
    "1. OpenAI 使用量最大，即便国内也是如此\n",
    "2. OpenAI 最好用，最先进，没有之一\n",
    "3. 其它模型都在追赶和模仿 OpenAI。学会 OpenAI，其它模型触类旁通；反之，不一定\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nOf4rvQ13si"
   },
   "source": [
    "## 六、体验编程调用 OpenAI API\n",
    "\n",
    "AI 课程的主打语言是 Python，因为：\n",
    "\n",
    "1. Python 和 AI 是天生的一对\n",
    "2. Python 是最容易学习的编程语言\n",
    "\n",
    "### 6.1、安装 OpenAI Python 库\n",
    "\n",
    "在命令行执行：\n",
    "\n",
    "```bash\n",
    "pip install --upgrade openai\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2、发一条消息\n",
    "\n",
    "体验给大模型注入新知识的代码竟如此简单。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "不好意思，周末是休息时间，不会有课程安排。如果有任何问题，可以在周一至周五与我联系。周末愉快！\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# 加载 .env 文件到环境变量\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# 初始化 OpenAI 服务。会自动从环境变量加载 OPENAI_API_KEY 和 OPENAI_BASE_URL\n",
    "client = OpenAI(\n",
    "    api_key = \"sk-COfXKJ3FshQbCrS4eRLWJ2R6fndZVPHOXk1HamEZXssAqh8C\",\n",
    "    base_url = \"https://api.fe8.cn/v1\"\n",
    ")\n",
    "\n",
    "# 消息\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"你是AI助手小瓜，是 AGI 课堂的助教。这门课每周二、四上课。\"  # 注入新知识\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"周末上课吗？\"  # 问问题。可以改改试试\n",
    "    },\n",
    "\n",
    "]\n",
    "\n",
    "# 调用 GPT-3.5\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "# 输出回复\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
